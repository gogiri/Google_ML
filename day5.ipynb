{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNAyFji1pKVTCnKahULjdAh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xATpuJElVQm1","executionInfo":{"status":"ok","timestamp":1716555025973,"user_tz":-540,"elapsed":4762,"user":{"displayName":"허진경 (나자바바)","userId":"08806215878196109838"}},"outputId":"21c9bfb4-0c66-4f42-b644-06f87c690c7b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 100)               1200      \n","                                                                 \n"," dropout (Dropout)           (None, 100)               0         \n","                                                                 \n"," batch_normalization (Batch  (None, 100)               400       \n"," Normalization)                                                  \n","                                                                 \n"," dense_1 (Dense)             (None, 200)               20200     \n","                                                                 \n"," dropout_1 (Dropout)         (None, 200)               0         \n","                                                                 \n"," batch_normalization_1 (Bat  (None, 200)               800       \n"," chNormalization)                                                \n","                                                                 \n"," dense_2 (Dense)             (None, 50)                10050     \n","                                                                 \n"," dropout_2 (Dropout)         (None, 50)                0         \n","                                                                 \n"," batch_normalization_2 (Bat  (None, 50)                200       \n"," chNormalization)                                                \n","                                                                 \n"," dense_3 (Dense)             (None, 6)                 306       \n","                                                                 \n","=================================================================\n","Total params: 33156 (129.52 KB)\n","Trainable params: 32456 (126.78 KB)\n","Non-trainable params: 700 (2.73 KB)\n","_________________________________________________________________\n"]}],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Input, BatchNormalization, Dropout\n","from tensorflow.keras.activations import softmax\n","from tensorflow.keras.initializers import RandomNormal\n","\n","model = Sequential()\n","model.add(Input(11))\n","model.add(Dense(100, activation=\"elu\", kernel_initializer=\"glorot_uniform\"))\n","model.add(Dropout(0.4))\n","model.add(BatchNormalization())\n","model.add(Dense(200, activation=\"elu\", kernel_initializer=\"he_uniform\"))\n","model.add(Dropout(0.3))\n","model.add(BatchNormalization())\n","model.add(Dense(50, activation=\"elu\", kernel_initializer=\"glorot_uniform\"))\n","model.add(Dropout(0.5))\n","model.add(BatchNormalization())\n","model.add(Dense(6, activation=softmax))\n","model.summary()\n","# Trainable param: weight, bias\n","# Nontrainable param: kernel size, pool size, stride, [gamma weight, beta weight, mean, var]"]},{"cell_type":"code","source":["model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n","              metrics=[\"accuracy\"])"],"metadata":{"id":"EVwXZfS_Ve9a","executionInfo":{"status":"ok","timestamp":1716555025973,"user_tz":-540,"elapsed":2,"user":{"displayName":"허진경 (나자바바)","userId":"08806215878196109838"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","redwine = pd.read_csv(\"winequality-red.csv\", sep=\";\")\n","X = redwine.iloc[:, :-1]\n","y = redwine.iloc[:, -1] - 3 # 와인 등급은 3~8만 있으므로"],"metadata":{"id":"gHSOoY3tll16","executionInfo":{"status":"ok","timestamp":1716555025973,"user_tz":-540,"elapsed":1,"user":{"displayName":"허진경 (나자바바)","userId":"08806215878196109838"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y)"],"metadata":{"id":"uAnxmXx-mUNg","executionInfo":{"status":"ok","timestamp":1716555026558,"user_tz":-540,"elapsed":586,"user":{"displayName":"허진경 (나자바바)","userId":"08806215878196109838"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["%%time\n","model.fit(X_train, y_train, batch_size=200, epochs=200)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"KEDSyx09mhDw","executionInfo":{"status":"ok","timestamp":1716555045146,"user_tz":-540,"elapsed":18589,"user":{"displayName":"허진경 (나자바바)","userId":"08806215878196109838"}},"outputId":"65b80891-ec83-4b4e-b3d2-3a3c4f22fa85"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","6/6 [==============================] - 4s 11ms/step - loss: 2.3389 - accuracy: 0.1701\n","Epoch 2/200\n","6/6 [==============================] - 0s 9ms/step - loss: 2.1806 - accuracy: 0.2210\n","Epoch 3/200\n","6/6 [==============================] - 0s 9ms/step - loss: 2.1157 - accuracy: 0.2585\n","Epoch 4/200\n","6/6 [==============================] - 0s 9ms/step - loss: 2.0911 - accuracy: 0.2602\n","Epoch 5/200\n","6/6 [==============================] - 0s 9ms/step - loss: 2.0135 - accuracy: 0.2869\n","Epoch 6/200\n","6/6 [==============================] - 0s 9ms/step - loss: 1.9473 - accuracy: 0.2952\n","Epoch 7/200\n","6/6 [==============================] - 0s 14ms/step - loss: 1.9052 - accuracy: 0.3011\n","Epoch 8/200\n","6/6 [==============================] - 0s 9ms/step - loss: 1.9021 - accuracy: 0.3161\n","Epoch 9/200\n","6/6 [==============================] - 0s 10ms/step - loss: 1.8331 - accuracy: 0.3253\n","Epoch 10/200\n","6/6 [==============================] - 0s 8ms/step - loss: 1.7980 - accuracy: 0.3378\n","Epoch 11/200\n","6/6 [==============================] - 0s 9ms/step - loss: 1.7258 - accuracy: 0.3486\n","Epoch 12/200\n","6/6 [==============================] - 0s 10ms/step - loss: 1.7429 - accuracy: 0.3736\n","Epoch 13/200\n","6/6 [==============================] - 0s 9ms/step - loss: 1.7078 - accuracy: 0.3903\n","Epoch 14/200\n","6/6 [==============================] - 0s 10ms/step - loss: 1.6812 - accuracy: 0.3795\n","Epoch 15/200\n","6/6 [==============================] - 0s 9ms/step - loss: 1.6655 - accuracy: 0.3978\n","Epoch 16/200\n","6/6 [==============================] - 0s 10ms/step - loss: 1.5946 - accuracy: 0.4287\n","Epoch 17/200\n","6/6 [==============================] - 0s 8ms/step - loss: 1.5885 - accuracy: 0.4178\n","Epoch 18/200\n","6/6 [==============================] - 0s 9ms/step - loss: 1.5348 - accuracy: 0.4178\n","Epoch 19/200\n","6/6 [==============================] - 0s 11ms/step - loss: 1.5501 - accuracy: 0.4245\n","Epoch 20/200\n","6/6 [==============================] - 0s 9ms/step - loss: 1.4950 - accuracy: 0.4462\n","Epoch 21/200\n","6/6 [==============================] - 0s 9ms/step - loss: 1.4615 - accuracy: 0.4587\n","Epoch 22/200\n","6/6 [==============================] - 0s 9ms/step - loss: 1.4756 - accuracy: 0.4462\n","Epoch 23/200\n","6/6 [==============================] - 0s 12ms/step - loss: 1.4443 - accuracy: 0.4587\n","Epoch 24/200\n","6/6 [==============================] - 0s 8ms/step - loss: 1.4337 - accuracy: 0.4595\n","Epoch 25/200\n","6/6 [==============================] - 0s 8ms/step - loss: 1.4073 - accuracy: 0.4570\n","Epoch 26/200\n","6/6 [==============================] - 0s 9ms/step - loss: 1.3794 - accuracy: 0.4604\n","Epoch 27/200\n","6/6 [==============================] - 0s 17ms/step - loss: 1.3517 - accuracy: 0.4737\n","Epoch 28/200\n","6/6 [==============================] - 0s 18ms/step - loss: 1.3580 - accuracy: 0.4696\n","Epoch 29/200\n","6/6 [==============================] - 0s 16ms/step - loss: 1.3280 - accuracy: 0.5021\n","Epoch 30/200\n","6/6 [==============================] - 0s 17ms/step - loss: 1.3426 - accuracy: 0.4779\n","Epoch 31/200\n","6/6 [==============================] - 0s 14ms/step - loss: 1.2833 - accuracy: 0.5104\n","Epoch 32/200\n","6/6 [==============================] - 0s 15ms/step - loss: 1.2890 - accuracy: 0.4962\n","Epoch 33/200\n","6/6 [==============================] - 0s 15ms/step - loss: 1.2823 - accuracy: 0.4929\n","Epoch 34/200\n","6/6 [==============================] - 0s 14ms/step - loss: 1.2643 - accuracy: 0.4971\n","Epoch 35/200\n","6/6 [==============================] - 0s 15ms/step - loss: 1.2724 - accuracy: 0.4971\n","Epoch 36/200\n","6/6 [==============================] - 0s 15ms/step - loss: 1.2156 - accuracy: 0.5038\n","Epoch 37/200\n","6/6 [==============================] - 0s 16ms/step - loss: 1.2181 - accuracy: 0.4962\n","Epoch 38/200\n","6/6 [==============================] - 0s 16ms/step - loss: 1.2065 - accuracy: 0.5179\n","Epoch 39/200\n","6/6 [==============================] - 0s 15ms/step - loss: 1.2009 - accuracy: 0.5288\n","Epoch 40/200\n","6/6 [==============================] - 0s 14ms/step - loss: 1.1844 - accuracy: 0.5304\n","Epoch 41/200\n","6/6 [==============================] - 0s 14ms/step - loss: 1.1906 - accuracy: 0.5338\n","Epoch 42/200\n","6/6 [==============================] - 0s 14ms/step - loss: 1.1669 - accuracy: 0.5188\n","Epoch 43/200\n","6/6 [==============================] - 0s 15ms/step - loss: 1.1907 - accuracy: 0.5213\n","Epoch 44/200\n","6/6 [==============================] - 0s 16ms/step - loss: 1.1502 - accuracy: 0.5455\n","Epoch 45/200\n","6/6 [==============================] - 0s 14ms/step - loss: 1.1576 - accuracy: 0.5254\n","Epoch 46/200\n","6/6 [==============================] - 0s 16ms/step - loss: 1.1416 - accuracy: 0.5371\n","Epoch 47/200\n","6/6 [==============================] - 0s 16ms/step - loss: 1.1112 - accuracy: 0.5505\n","Epoch 48/200\n","6/6 [==============================] - 0s 17ms/step - loss: 1.1387 - accuracy: 0.5188\n","Epoch 49/200\n","6/6 [==============================] - 0s 17ms/step - loss: 1.1239 - accuracy: 0.5430\n","Epoch 50/200\n","6/6 [==============================] - 0s 15ms/step - loss: 1.1039 - accuracy: 0.5371\n","Epoch 51/200\n","6/6 [==============================] - 0s 16ms/step - loss: 1.1291 - accuracy: 0.5188\n","Epoch 52/200\n","6/6 [==============================] - 0s 17ms/step - loss: 1.1134 - accuracy: 0.5413\n","Epoch 53/200\n","6/6 [==============================] - 0s 15ms/step - loss: 1.1102 - accuracy: 0.5221\n","Epoch 54/200\n","6/6 [==============================] - 0s 14ms/step - loss: 1.0840 - accuracy: 0.5496\n","Epoch 55/200\n","6/6 [==============================] - 0s 15ms/step - loss: 1.0897 - accuracy: 0.5496\n","Epoch 56/200\n","6/6 [==============================] - 0s 17ms/step - loss: 1.0830 - accuracy: 0.5580\n","Epoch 57/200\n","6/6 [==============================] - 0s 15ms/step - loss: 1.0748 - accuracy: 0.5563\n","Epoch 58/200\n","6/6 [==============================] - 0s 17ms/step - loss: 1.0858 - accuracy: 0.5463\n","Epoch 59/200\n","6/6 [==============================] - 0s 17ms/step - loss: 1.0604 - accuracy: 0.5488\n","Epoch 60/200\n","6/6 [==============================] - 0s 16ms/step - loss: 1.0471 - accuracy: 0.5338\n","Epoch 61/200\n","6/6 [==============================] - 0s 15ms/step - loss: 1.0702 - accuracy: 0.5513\n","Epoch 62/200\n","6/6 [==============================] - 0s 15ms/step - loss: 1.0679 - accuracy: 0.5438\n","Epoch 63/200\n","6/6 [==============================] - 0s 15ms/step - loss: 1.0172 - accuracy: 0.5755\n","Epoch 64/200\n","6/6 [==============================] - 0s 15ms/step - loss: 1.0371 - accuracy: 0.5605\n","Epoch 65/200\n","6/6 [==============================] - 0s 15ms/step - loss: 1.0560 - accuracy: 0.5605\n","Epoch 66/200\n","6/6 [==============================] - 0s 15ms/step - loss: 1.0345 - accuracy: 0.5580\n","Epoch 67/200\n","6/6 [==============================] - 0s 16ms/step - loss: 1.0404 - accuracy: 0.5513\n","Epoch 68/200\n","6/6 [==============================] - 0s 16ms/step - loss: 1.0287 - accuracy: 0.5646\n","Epoch 69/200\n","6/6 [==============================] - 0s 16ms/step - loss: 1.0468 - accuracy: 0.5621\n","Epoch 70/200\n","6/6 [==============================] - 0s 15ms/step - loss: 1.0428 - accuracy: 0.5613\n","Epoch 71/200\n","6/6 [==============================] - 0s 12ms/step - loss: 1.0387 - accuracy: 0.5505\n","Epoch 72/200\n","6/6 [==============================] - 0s 9ms/step - loss: 1.0273 - accuracy: 0.5638\n","Epoch 73/200\n","6/6 [==============================] - 0s 9ms/step - loss: 1.0117 - accuracy: 0.5922\n","Epoch 74/200\n","6/6 [==============================] - 0s 9ms/step - loss: 1.0381 - accuracy: 0.5671\n","Epoch 75/200\n","6/6 [==============================] - 0s 9ms/step - loss: 1.0376 - accuracy: 0.5546\n","Epoch 76/200\n","6/6 [==============================] - 0s 9ms/step - loss: 1.0100 - accuracy: 0.5738\n","Epoch 77/200\n","6/6 [==============================] - 0s 9ms/step - loss: 1.0146 - accuracy: 0.5655\n","Epoch 78/200\n","6/6 [==============================] - 0s 8ms/step - loss: 1.0158 - accuracy: 0.5746\n","Epoch 79/200\n","6/6 [==============================] - 0s 9ms/step - loss: 1.0353 - accuracy: 0.5530\n","Epoch 80/200\n","6/6 [==============================] - 0s 9ms/step - loss: 1.0256 - accuracy: 0.5555\n","Epoch 81/200\n","6/6 [==============================] - 0s 11ms/step - loss: 0.9988 - accuracy: 0.5771\n","Epoch 82/200\n","6/6 [==============================] - 0s 10ms/step - loss: 1.0175 - accuracy: 0.5488\n","Epoch 83/200\n","6/6 [==============================] - 0s 11ms/step - loss: 1.0001 - accuracy: 0.5680\n","Epoch 84/200\n","6/6 [==============================] - 0s 9ms/step - loss: 1.0198 - accuracy: 0.5605\n","Epoch 85/200\n","6/6 [==============================] - 0s 9ms/step - loss: 1.0246 - accuracy: 0.5630\n","Epoch 86/200\n","6/6 [==============================] - 0s 10ms/step - loss: 1.0193 - accuracy: 0.5763\n","Epoch 87/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9954 - accuracy: 0.5671\n","Epoch 88/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9868 - accuracy: 0.5730\n","Epoch 89/200\n","6/6 [==============================] - 0s 9ms/step - loss: 1.0053 - accuracy: 0.5897\n","Epoch 90/200\n","6/6 [==============================] - 0s 9ms/step - loss: 1.0036 - accuracy: 0.5705\n","Epoch 91/200\n","6/6 [==============================] - 0s 9ms/step - loss: 1.0001 - accuracy: 0.5888\n","Epoch 92/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9835 - accuracy: 0.5713\n","Epoch 93/200\n","6/6 [==============================] - 0s 11ms/step - loss: 0.9886 - accuracy: 0.5805\n","Epoch 94/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9836 - accuracy: 0.5755\n","Epoch 95/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9915 - accuracy: 0.5813\n","Epoch 96/200\n","6/6 [==============================] - 0s 15ms/step - loss: 1.0091 - accuracy: 0.5705\n","Epoch 97/200\n","6/6 [==============================] - 0s 12ms/step - loss: 0.9803 - accuracy: 0.5763\n","Epoch 98/200\n","6/6 [==============================] - 0s 10ms/step - loss: 0.9972 - accuracy: 0.5838\n","Epoch 99/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9897 - accuracy: 0.5888\n","Epoch 100/200\n","6/6 [==============================] - 0s 9ms/step - loss: 1.0062 - accuracy: 0.5713\n","Epoch 101/200\n","6/6 [==============================] - 0s 10ms/step - loss: 0.9960 - accuracy: 0.5872\n","Epoch 102/200\n","6/6 [==============================] - 0s 10ms/step - loss: 0.9949 - accuracy: 0.5730\n","Epoch 103/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9993 - accuracy: 0.5755\n","Epoch 104/200\n","6/6 [==============================] - 0s 10ms/step - loss: 0.9842 - accuracy: 0.5897\n","Epoch 105/200\n","6/6 [==============================] - 0s 8ms/step - loss: 0.9782 - accuracy: 0.5855\n","Epoch 106/200\n","6/6 [==============================] - 0s 8ms/step - loss: 0.9920 - accuracy: 0.5805\n","Epoch 107/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9775 - accuracy: 0.5788\n","Epoch 108/200\n","6/6 [==============================] - 0s 9ms/step - loss: 1.0044 - accuracy: 0.5688\n","Epoch 109/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9655 - accuracy: 0.5771\n","Epoch 110/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9882 - accuracy: 0.5730\n","Epoch 111/200\n","6/6 [==============================] - 0s 12ms/step - loss: 0.9985 - accuracy: 0.5730\n","Epoch 112/200\n","6/6 [==============================] - 0s 10ms/step - loss: 0.9794 - accuracy: 0.5922\n","Epoch 113/200\n","6/6 [==============================] - 0s 15ms/step - loss: 0.9940 - accuracy: 0.5880\n","Epoch 114/200\n","6/6 [==============================] - 0s 10ms/step - loss: 0.9795 - accuracy: 0.5738\n","Epoch 115/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9632 - accuracy: 0.5755\n","Epoch 116/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9829 - accuracy: 0.5930\n","Epoch 117/200\n","6/6 [==============================] - 0s 10ms/step - loss: 0.9857 - accuracy: 0.5905\n","Epoch 118/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9817 - accuracy: 0.5905\n","Epoch 119/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9626 - accuracy: 0.5847\n","Epoch 120/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9750 - accuracy: 0.5880\n","Epoch 121/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9858 - accuracy: 0.5788\n","Epoch 122/200\n","6/6 [==============================] - 0s 8ms/step - loss: 0.9800 - accuracy: 0.5805\n","Epoch 123/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9730 - accuracy: 0.5897\n","Epoch 124/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9694 - accuracy: 0.5913\n","Epoch 125/200\n","6/6 [==============================] - 0s 10ms/step - loss: 0.9757 - accuracy: 0.5913\n","Epoch 126/200\n","6/6 [==============================] - 0s 14ms/step - loss: 0.9958 - accuracy: 0.5771\n","Epoch 127/200\n","6/6 [==============================] - 0s 10ms/step - loss: 0.9886 - accuracy: 0.5663\n","Epoch 128/200\n","6/6 [==============================] - 0s 10ms/step - loss: 0.9902 - accuracy: 0.5655\n","Epoch 129/200\n","6/6 [==============================] - 0s 10ms/step - loss: 0.9831 - accuracy: 0.5755\n","Epoch 130/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9617 - accuracy: 0.5888\n","Epoch 131/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9797 - accuracy: 0.5947\n","Epoch 132/200\n","6/6 [==============================] - 0s 11ms/step - loss: 0.9782 - accuracy: 0.5830\n","Epoch 133/200\n","6/6 [==============================] - 0s 10ms/step - loss: 0.9894 - accuracy: 0.5905\n","Epoch 134/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9891 - accuracy: 0.5855\n","Epoch 135/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9730 - accuracy: 0.5755\n","Epoch 136/200\n","6/6 [==============================] - 0s 8ms/step - loss: 0.9702 - accuracy: 0.5822\n","Epoch 137/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9572 - accuracy: 0.5863\n","Epoch 138/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9658 - accuracy: 0.5938\n","Epoch 139/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9637 - accuracy: 0.5897\n","Epoch 140/200\n","6/6 [==============================] - 0s 10ms/step - loss: 0.9579 - accuracy: 0.5880\n","Epoch 141/200\n","6/6 [==============================] - 0s 13ms/step - loss: 0.9551 - accuracy: 0.5938\n","Epoch 142/200\n","6/6 [==============================] - 0s 10ms/step - loss: 0.9781 - accuracy: 0.5838\n","Epoch 143/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9537 - accuracy: 0.5955\n","Epoch 144/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9744 - accuracy: 0.5780\n","Epoch 145/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9717 - accuracy: 0.5830\n","Epoch 146/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9698 - accuracy: 0.5930\n","Epoch 147/200\n","6/6 [==============================] - 0s 10ms/step - loss: 0.9772 - accuracy: 0.5847\n","Epoch 148/200\n","6/6 [==============================] - 0s 12ms/step - loss: 0.9645 - accuracy: 0.5922\n","Epoch 149/200\n","6/6 [==============================] - 0s 10ms/step - loss: 0.9544 - accuracy: 0.5897\n","Epoch 150/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9583 - accuracy: 0.5988\n","Epoch 151/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9701 - accuracy: 0.5788\n","Epoch 152/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9507 - accuracy: 0.5847\n","Epoch 153/200\n","6/6 [==============================] - 0s 10ms/step - loss: 0.9785 - accuracy: 0.5796\n","Epoch 154/200\n","6/6 [==============================] - 0s 10ms/step - loss: 0.9720 - accuracy: 0.5713\n","Epoch 155/200\n","6/6 [==============================] - 0s 10ms/step - loss: 0.9458 - accuracy: 0.5997\n","Epoch 156/200\n","6/6 [==============================] - 0s 15ms/step - loss: 0.9470 - accuracy: 0.5930\n","Epoch 157/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9677 - accuracy: 0.5805\n","Epoch 158/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9620 - accuracy: 0.5980\n","Epoch 159/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9633 - accuracy: 0.5847\n","Epoch 160/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9588 - accuracy: 0.5972\n","Epoch 161/200\n","6/6 [==============================] - 0s 13ms/step - loss: 0.9561 - accuracy: 0.5847\n","Epoch 162/200\n","6/6 [==============================] - 0s 10ms/step - loss: 0.9595 - accuracy: 0.5947\n","Epoch 163/200\n","6/6 [==============================] - 0s 10ms/step - loss: 0.9533 - accuracy: 0.5913\n","Epoch 164/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9661 - accuracy: 0.5713\n","Epoch 165/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9648 - accuracy: 0.5972\n","Epoch 166/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9622 - accuracy: 0.5997\n","Epoch 167/200\n","6/6 [==============================] - 0s 10ms/step - loss: 0.9541 - accuracy: 0.5888\n","Epoch 168/200\n","6/6 [==============================] - 0s 10ms/step - loss: 0.9472 - accuracy: 0.5847\n","Epoch 169/200\n","6/6 [==============================] - 0s 10ms/step - loss: 0.9640 - accuracy: 0.5980\n","Epoch 170/200\n","6/6 [==============================] - 0s 12ms/step - loss: 0.9767 - accuracy: 0.5872\n","Epoch 171/200\n","6/6 [==============================] - 0s 14ms/step - loss: 0.9620 - accuracy: 0.5872\n","Epoch 172/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9676 - accuracy: 0.5780\n","Epoch 173/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9531 - accuracy: 0.5972\n","Epoch 174/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9667 - accuracy: 0.5763\n","Epoch 175/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9534 - accuracy: 0.6072\n","Epoch 176/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9586 - accuracy: 0.5780\n","Epoch 177/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9567 - accuracy: 0.5880\n","Epoch 178/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9631 - accuracy: 0.5972\n","Epoch 179/200\n","6/6 [==============================] - 0s 8ms/step - loss: 0.9540 - accuracy: 0.5922\n","Epoch 180/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9537 - accuracy: 0.5980\n","Epoch 181/200\n","6/6 [==============================] - 0s 8ms/step - loss: 0.9401 - accuracy: 0.5905\n","Epoch 182/200\n","6/6 [==============================] - 0s 12ms/step - loss: 0.9568 - accuracy: 0.5905\n","Epoch 183/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9591 - accuracy: 0.5855\n","Epoch 184/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9447 - accuracy: 0.6022\n","Epoch 185/200\n","6/6 [==============================] - 0s 10ms/step - loss: 0.9578 - accuracy: 0.5963\n","Epoch 186/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9508 - accuracy: 0.5930\n","Epoch 187/200\n","6/6 [==============================] - 0s 12ms/step - loss: 0.9436 - accuracy: 0.5997\n","Epoch 188/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9445 - accuracy: 0.5947\n","Epoch 189/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9592 - accuracy: 0.5805\n","Epoch 190/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9440 - accuracy: 0.5938\n","Epoch 191/200\n","6/6 [==============================] - 0s 10ms/step - loss: 0.9526 - accuracy: 0.5822\n","Epoch 192/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9522 - accuracy: 0.5980\n","Epoch 193/200\n","6/6 [==============================] - 0s 10ms/step - loss: 0.9598 - accuracy: 0.5863\n","Epoch 194/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9492 - accuracy: 0.5922\n","Epoch 195/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9561 - accuracy: 0.5897\n","Epoch 196/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9434 - accuracy: 0.5972\n","Epoch 197/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9456 - accuracy: 0.6130\n","Epoch 198/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9280 - accuracy: 0.5997\n","Epoch 199/200\n","6/6 [==============================] - 0s 10ms/step - loss: 0.9456 - accuracy: 0.6080\n","Epoch 200/200\n","6/6 [==============================] - 0s 11ms/step - loss: 0.9520 - accuracy: 0.6013\n","CPU times: user 20.6 s, sys: 918 ms, total: 21.5 s\n","Wall time: 18.6 s\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7da3f999b8e0>"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["model.evaluate(X_test, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j9VYkuFFmxMJ","executionInfo":{"status":"ok","timestamp":1716555045617,"user_tz":-540,"elapsed":473,"user":{"displayName":"허진경 (나자바바)","userId":"08806215878196109838"}},"outputId":"1ff07fe3-dc93-468e-f4a5-eb43aabb76a7"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["13/13 [==============================] - 0s 3ms/step - loss: 0.9576 - accuracy: 0.5925\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.9575785994529724, 0.5924999713897705]"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":[],"metadata":{"id":"frCFY0Ydn2jq","executionInfo":{"status":"ok","timestamp":1716555045618,"user_tz":-540,"elapsed":2,"user":{"displayName":"허진경 (나자바바)","userId":"08806215878196109838"}}},"execution_count":6,"outputs":[]}]}