{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "718e3bb8-527a-46c6-9fc4-0328a064bfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import SimpleRNN, Dense, Input, Embedding\n",
    "# model = Sequential()\n",
    "# model.add(Input(shape=(80))) # 입력하는 영화평의 길이를 80으로 제한, 길면 자르고, 짧으면 zero padding\n",
    "# model.add(Embedding(input_dim=10000, output_dim=32))\n",
    "# model.add(SimpleRNN(64))\n",
    "# # model.add(Dense(1, activation='sigmoid'))\n",
    "# model.add(Dense(2, activation='softmax'))\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0301e58-356f-4ddc-809b-1101ec275e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Head Attention\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Layer\n",
    "import numpy as np\n",
    "\n",
    "class MultiHeadAttention(Layer):\n",
    "    def __init__(self, num_heads, key_dim):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads # 헤드의 수\n",
    "        self.key_dim = key_dim # 각 헤드의 차원\n",
    "        self.depth = key_dim // num_heads # 각 헤드의 깊이, shape 변경 \n",
    "\n",
    "        self.wq = Dense(key_dim) # q = self.wq(q)\n",
    "        self.wk = Dense(key_dim)\n",
    "        self.wv = Dense(key_dim)\n",
    "\n",
    "        self.dense = Dense(key_dim) # 출력 레이어\n",
    "\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        # 텐서의 모양을 batch_size, seq_len, key_dim -> batch_size, num_heads, seq_len, depth\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        \n",
    "        \n",
    "    # 모델을 만들어 반환\n",
    "    # MultiHeadAttention(3, 32)(v, k, q) <- v, k, q는 모두 pos_enc_output이 전달\n",
    "    def call(self, v, k, q): \n",
    "        # 입력 텐서가 weight와 결합되어서 q, k, v로 변환\n",
    "        q = self.wq(q)\n",
    "        k = self.wk(k)\n",
    "        v = self.wv(v)\n",
    "\n",
    "        # ndarray.shape -> 2,3,4\n",
    "        # tf.shape(텐서) -> 2,3,4 -> 2가 배치크기, shape 중에서 0번째꺼\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        # 각 헤드로 분할\n",
    "        q = self.split_heads(q, batch_size)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "\n",
    "        # scaled dot product 계산\n",
    "        matmul_qk = tf.matmul(q, k, transpose_b=True) # Q @ K.T\n",
    "        dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "        scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "        scaled_attention = tf.matmul(attention_weights, v)\n",
    "        \n",
    "        # 각 헤드의 출력을 결합해서 원래의 형태로 변환\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0,2,1,3])\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.key_dim))\n",
    "\n",
    "        output = self.dense(concat_attention)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbe72b59-1853-4160-83c5-a7146417bdac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 80)]                 0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, 80, 32)               320000    ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOp  (None, 80, 32)               0         ['embedding[0][0]']           \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention (Mult  (None, None, 32)             4224      ['tf.__operators__.add[0][0]',\n",
      " iHeadAttention)                                                     'tf.__operators__.add[0][0]',\n",
      "                                                                     'tf.__operators__.add[0][0]']\n",
      "                                                                                                  \n",
      " add (Add)                   (None, 80, 32)               0         ['tf.__operators__.add[0][0]',\n",
      "                                                                     'multi_head_attention[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 80, 32)               128       ['add[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " sequential (Sequential)     (None, 80, 32)               4192      ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " add_1 (Add)                 (None, 80, 32)               0         ['sequential[0][0]',          \n",
      "                                                                     'batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 80, 32)               128       ['add_1[0][0]']               \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d (  (None, 32)                   0         ['batch_normalization_1[0][0]'\n",
      " GlobalAveragePooling1D)                                            ]                             \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 64)                   2112      ['global_average_pooling1d[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 2)                    130       ['dense_6[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 330914 (1.26 MB)\n",
      "Trainable params: 330786 (1.26 MB)\n",
      "Non-trainable params: 128 (512.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 트랜스포머를 이용한 영화평 분류 모델\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "inputs = layers.Input(shape=(80,))\n",
    "\n",
    "input_embedding = layers.Embedding(input_dim=10000, output_dim=32)(inputs)\n",
    "positions = tf.range(0, 80)\n",
    "pos_encoding = layers.Embedding(input_dim=80, output_dim=32)(positions)\n",
    "pos_enc_output = pos_encoding + input_embedding\n",
    "\n",
    "# attention_output = layers.MultiHeadAttention(3, 32)(pos_enc_output, pos_enc_output)\n",
    "attention_output = MultiHeadAttention(2, 32)(pos_enc_output, pos_enc_output, pos_enc_output)\n",
    "x = layers.add([pos_enc_output, attention_output])\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "ffnn = Sequential([layers.Dense(64, activation='relu'),\n",
    "                   layers.Dense(32, activation='relu')])(x)\n",
    "x = layers.add([ffnn, x])\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "# x = layers.Dropout(0.1)(x)\n",
    "\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "# x = layers.Dropout(0.1)(x)\n",
    "\n",
    "outputs = layers.Dense(2, activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d441c95-8cfa-424c-bff7-0ca07b5ee8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss='binary_crossentropy', optimizer='adam',\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6eb67f2f-7b73-4513-a2aa-7ddb5fd27cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44186ecb-7929-43c3-9bac-d7b17370b26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,) (25000,) (25000,) (25000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa42034c-aa02-43c3-9a2d-25bc97d1ef2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12e4c77e-98b7-41f2-987d-ab32ea45e95e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "word_index['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5522cb80-c068-4b89-9152-db2a84310941",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "X_train = pad_sequences(X_train, maxlen=80)\n",
    "X_test = pad_sequences(X_test, maxlen=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cf49cac-73fd-4f6c-bf10-7410080c3fee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "125/125 [==============================] - 10s 69ms/step - loss: 0.4466 - accuracy: 0.7841\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 8s 66ms/step - loss: 0.2778 - accuracy: 0.8826\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 8s 66ms/step - loss: 0.2248 - accuracy: 0.9075\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 8s 64ms/step - loss: 0.1769 - accuracy: 0.9251\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 8s 64ms/step - loss: 0.1350 - accuracy: 0.9426\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 8s 64ms/step - loss: 0.0943 - accuracy: 0.9626\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 8s 66ms/step - loss: 0.0659 - accuracy: 0.9752\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 8s 65ms/step - loss: 0.0469 - accuracy: 0.9823\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 9s 72ms/step - loss: 0.0358 - accuracy: 0.9874\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 9s 75ms/step - loss: 0.0238 - accuracy: 0.9920\n",
      "CPU times: total: 5min 30s\n",
      "Wall time: 1min 26s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x23241159990>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9592949-9039-4f56-b4c7-aaf10dda66b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 4s 5ms/step - loss: 1.3262 - accuracy: 0.7930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3262144327163696, 0.792959988117218]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9871fb65-5168-4700-b0fc-ceea109d6cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 80)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e78be4ad-f3bc-4491-aa19-19ea405b5355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 4s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "pred = model.predict(X_test)\n",
    "# pred = (pred > 0.5).astype(int)\n",
    "pred = np.argmax(pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32d81e2f-79b0-4951-9cb9-7ff0ec51ed97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10409  2091]\n",
      " [ 3085  9415]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e50b5985-3cad-4ea8-a6d3-b249ee5bc058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79296"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6faa2dfe-31ca-4c18-b127-414c65da9aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵티마이저를 sgd로 바꿔보세요. accuracy: 0.57784\n",
    "# 전체 단어의 개수를 1000개로 바꿔보세요. accuracy: 0.72104\n",
    "# 영화평의 길이를 200개로 바꿔보세요. accuracy: 0.51976, 0.50936\n",
    "# pad_sequence의 truncating과 padding을 pre로 바꿔보세요. accuracy: 0.81016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f55eb1d-900e-4701-96eb-49e0e17813df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래 택스트를 긍/부정 분류하세요.\n",
    "text = \"My God the actors who potrayed the VIP people cannot act. I cringed everytime they said a line. It felt like they were just reading them. Even the intonation was off. It was like when we were kids and had to read a play in class and we exagerated the intonation. Terrible, just awful.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2cab44f-8af3-470a-936a-0499274f90d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 안에 사용한 10000의 단어집에 없는 단어가 있을 수 있음\n",
    "# 사용하지 않는 단어가 있을 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0aff83b6-e83b-4f23-8489-d4eac007b59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "# print(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "611b2fe0-5b50-4310-9efc-1d15a8c694a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index = {k:(v+3) for k, v in word_index.items()}\n",
    "# 특별한 문자를 4개 미리 넣어둠 <PAD>, <START>, <UNK>, <UNUSED>\n",
    "word_to_index[\"<PAD>\"] = 0\n",
    "word_to_index[\"<START>\"] = 1\n",
    "word_to_index[\"<UNK>\"] = 2\n",
    "word_to_index[\"<UNUSED>\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4756bcd4-a895-4fe9-b2bf-1b60f50e80bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 558, 61]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encoding(review_text):\n",
    "    encoded = []\n",
    "    for word in review_text:\n",
    "        try:\n",
    "            idx = word_to_index[word]\n",
    "            if idx>10000:\n",
    "                encoded.append(3)\n",
    "            else:\n",
    "                encoded.append(idx)\n",
    "        except:\n",
    "            encoded.append(2)\n",
    "    return encoded\n",
    "\n",
    "encoding(['the', 'god', 'my'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc337373-cbe6-4cb2-b2d6-aa3b93047ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my', 'god', 'the', 'actors', 'who', 'potrayed', 'the', 'vip', 'people', 'cannot', 'act.', 'i', 'cringed', 'everytime', 'they', 'said', 'a', 'line.', 'it', 'felt', 'like', 'they', 'were', 'just', 'reading', 'them.', 'even', 'the', 'intonation', 'was', 'off.', 'it', 'was', 'like', 'when', 'we', 'were', 'kids', 'and', 'had', 'to', 'read', 'a', 'play', 'in', 'class', 'and', 'we', 'exagerated', 'the', 'intonation.', 'terrible,', 'just', 'awful.']\n",
      "[61, 558, 4, 156, 37, 2, 4, 3, 84, 566, 2, 13, 3, 3, 36, 301, 6, 2, 12, 421, 40, 36, 71, 43, 886, 2, 60, 4, 3, 16, 2, 12, 16, 40, 54, 75, 71, 362, 5, 69, 8, 332, 6, 297, 11, 707, 5, 75, 3, 4, 2, 2, 43, 2]\n"
     ]
    }
   ],
   "source": [
    "input_text = text.lower().split()\n",
    "print(input_text)\n",
    "input_encoded = encoding(input_text)\n",
    "print(input_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b64b095e-fd8f-4cb2-96ca-395d51f06116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 61, 558,   4, 156,  37,   2,   4,   3,  84, 566,   2,  13,   3,\n",
       "          3,  36, 301,   6,   2,  12, 421,  40,  36,  71,  43, 886,   2,\n",
       "         60,   4,   3,  16,   2,  12,  16,  40,  54,  75,  71, 362,   5,\n",
       "         69,   8, 332,   6, 297,  11, 707,   5,  75,   3,   4,   2,   2,\n",
       "         43,   2]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.array(input_encoded).reshape(-1, len(input_encoded))\n",
    "np.array(input_encoded)[np.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1bf1b8a4-dbaf-44e0-9ebc-22758400b141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0  61 558   4 156  37   2   4   3  84 566\n",
      "    2  13   3   3  36 301   6   2  12 421  40  36  71  43 886   2  60   4\n",
      "    3  16   2  12  16  40  54  75  71 362   5  69   8 332   6 297  11 707\n",
      "    5  75   3   4   2   2  43   2]]\n"
     ]
    }
   ],
   "source": [
    "input_pad = pad_sequences(np.array(input_encoded)[np.newaxis, :], maxlen=80)\n",
    "print(input_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97f10918-9d69-433d-aa92-b1a50e87ce76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[9.9942786e-01, 5.7208783e-04]], dtype=float32), 0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1 = model.predict(input_pad)\n",
    "pred1, np.argmax(pred1) #0: 부정, 1: 긍정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3311659-492a-49c2-9d75-d7a5da2a9c63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
